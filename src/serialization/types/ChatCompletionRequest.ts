/**
 * This file was auto-generated by Fern from our API Definition.
 */

import * as serializers from "../index";
import * as Letta from "../../api/index";
import * as core from "../../core";
import { ChatCompletionRequestMessagesItem } from "./ChatCompletionRequestMessagesItem";
import { ResponseFormat } from "./ResponseFormat";
import { ChatCompletionRequestStop } from "./ChatCompletionRequestStop";
import { ToolInput } from "./ToolInput";
import { ChatCompletionRequestToolChoice } from "./ChatCompletionRequestToolChoice";
import { FunctionSchema } from "./FunctionSchema";
import { ChatCompletionRequestFunctionCall } from "./ChatCompletionRequestFunctionCall";

export const ChatCompletionRequest: core.serialization.ObjectSchema<
    serializers.ChatCompletionRequest.Raw,
    Letta.ChatCompletionRequest
> = core.serialization.object({
    model: core.serialization.string(),
    messages: core.serialization.list(ChatCompletionRequestMessagesItem),
    frequencyPenalty: core.serialization.property("frequency_penalty", core.serialization.number().optional()),
    logitBias: core.serialization.property(
        "logit_bias",
        core.serialization.record(core.serialization.string(), core.serialization.number().optional()).optional(),
    ),
    logprobs: core.serialization.boolean().optional(),
    topLogprobs: core.serialization.property("top_logprobs", core.serialization.number().optional()),
    maxTokens: core.serialization.property("max_tokens", core.serialization.number().optional()),
    n: core.serialization.number().optional(),
    presencePenalty: core.serialization.property("presence_penalty", core.serialization.number().optional()),
    responseFormat: core.serialization.property("response_format", ResponseFormat.optional()),
    seed: core.serialization.number().optional(),
    stop: ChatCompletionRequestStop.optional(),
    stream: core.serialization.boolean().optional(),
    temperature: core.serialization.number().optional(),
    topP: core.serialization.property("top_p", core.serialization.number().optional()),
    user: core.serialization.string().optional(),
    tools: core.serialization.list(ToolInput).optional(),
    toolChoice: core.serialization.property("tool_choice", ChatCompletionRequestToolChoice.optional()),
    functions: core.serialization.list(FunctionSchema).optional(),
    functionCall: core.serialization.property("function_call", ChatCompletionRequestFunctionCall.optional()),
});

export declare namespace ChatCompletionRequest {
    export interface Raw {
        model: string;
        messages: ChatCompletionRequestMessagesItem.Raw[];
        frequency_penalty?: number | null;
        logit_bias?: Record<string, number | null | undefined> | null;
        logprobs?: boolean | null;
        top_logprobs?: number | null;
        max_tokens?: number | null;
        n?: number | null;
        presence_penalty?: number | null;
        response_format?: ResponseFormat.Raw | null;
        seed?: number | null;
        stop?: ChatCompletionRequestStop.Raw | null;
        stream?: boolean | null;
        temperature?: number | null;
        top_p?: number | null;
        user?: string | null;
        tools?: ToolInput.Raw[] | null;
        tool_choice?: ChatCompletionRequestToolChoice.Raw | null;
        functions?: FunctionSchema.Raw[] | null;
        function_call?: ChatCompletionRequestFunctionCall.Raw | null;
    }
}
