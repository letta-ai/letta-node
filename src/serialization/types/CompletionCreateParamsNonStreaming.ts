/**
 * This file was auto-generated by Fern from our API Definition.
 */

import * as serializers from "../index";
import * as Letta from "../../api/index";
import * as core from "../../core";
import { CompletionCreateParamsNonStreamingMessagesItem } from "./CompletionCreateParamsNonStreamingMessagesItem";
import { CompletionCreateParamsNonStreamingModel } from "./CompletionCreateParamsNonStreamingModel";
import { ChatCompletionAudioParam } from "./ChatCompletionAudioParam";
import { CompletionCreateParamsNonStreamingFunctionCall } from "./CompletionCreateParamsNonStreamingFunctionCall";
import { OpenaiTypesChatCompletionCreateParamsFunction } from "./OpenaiTypesChatCompletionCreateParamsFunction";
import { CompletionCreateParamsNonStreamingModalitiesItem } from "./CompletionCreateParamsNonStreamingModalitiesItem";
import { ChatCompletionPredictionContentParam } from "./ChatCompletionPredictionContentParam";
import { CompletionCreateParamsNonStreamingReasoningEffort } from "./CompletionCreateParamsNonStreamingReasoningEffort";
import { CompletionCreateParamsNonStreamingResponseFormat } from "./CompletionCreateParamsNonStreamingResponseFormat";
import { CompletionCreateParamsNonStreamingServiceTier } from "./CompletionCreateParamsNonStreamingServiceTier";
import { CompletionCreateParamsNonStreamingStop } from "./CompletionCreateParamsNonStreamingStop";
import { ChatCompletionStreamOptionsParam } from "./ChatCompletionStreamOptionsParam";
import { CompletionCreateParamsNonStreamingToolChoice } from "./CompletionCreateParamsNonStreamingToolChoice";
import { ChatCompletionToolParam } from "./ChatCompletionToolParam";

export const CompletionCreateParamsNonStreaming: core.serialization.ObjectSchema<
    serializers.CompletionCreateParamsNonStreaming.Raw,
    Letta.CompletionCreateParamsNonStreaming
> = core.serialization.object({
    messages: core.serialization.list(CompletionCreateParamsNonStreamingMessagesItem),
    model: CompletionCreateParamsNonStreamingModel,
    audio: ChatCompletionAudioParam.optional(),
    frequencyPenalty: core.serialization.property("frequency_penalty", core.serialization.number().optional()),
    functionCall: core.serialization.property(
        "function_call",
        CompletionCreateParamsNonStreamingFunctionCall.optional(),
    ),
    functions: core.serialization.list(OpenaiTypesChatCompletionCreateParamsFunction).optional(),
    logitBias: core.serialization.property(
        "logit_bias",
        core.serialization.record(core.serialization.string(), core.serialization.number().optional()).optional(),
    ),
    logprobs: core.serialization.boolean().optional(),
    maxCompletionTokens: core.serialization.property("max_completion_tokens", core.serialization.number().optional()),
    maxTokens: core.serialization.property("max_tokens", core.serialization.number().optional()),
    metadata: core.serialization.record(core.serialization.string(), core.serialization.string().optional()).optional(),
    modalities: core.serialization.list(CompletionCreateParamsNonStreamingModalitiesItem).optional(),
    n: core.serialization.number().optional(),
    parallelToolCalls: core.serialization.property("parallel_tool_calls", core.serialization.boolean().optional()),
    prediction: ChatCompletionPredictionContentParam.optional(),
    presencePenalty: core.serialization.property("presence_penalty", core.serialization.number().optional()),
    reasoningEffort: core.serialization.property(
        "reasoning_effort",
        CompletionCreateParamsNonStreamingReasoningEffort.optional(),
    ),
    responseFormat: core.serialization.property(
        "response_format",
        CompletionCreateParamsNonStreamingResponseFormat.optional(),
    ),
    seed: core.serialization.number().optional(),
    serviceTier: core.serialization.property("service_tier", CompletionCreateParamsNonStreamingServiceTier.optional()),
    stop: CompletionCreateParamsNonStreamingStop.optional(),
    store: core.serialization.boolean().optional(),
    streamOptions: core.serialization.property("stream_options", ChatCompletionStreamOptionsParam.optional()),
    temperature: core.serialization.number().optional(),
    toolChoice: core.serialization.property("tool_choice", CompletionCreateParamsNonStreamingToolChoice.optional()),
    tools: core.serialization.list(ChatCompletionToolParam).optional(),
    topLogprobs: core.serialization.property("top_logprobs", core.serialization.number().optional()),
    topP: core.serialization.property("top_p", core.serialization.number().optional()),
    user: core.serialization.string().optional(),
    stream: core.serialization.boolean().optional(),
});

export declare namespace CompletionCreateParamsNonStreaming {
    export interface Raw {
        messages: CompletionCreateParamsNonStreamingMessagesItem.Raw[];
        model: CompletionCreateParamsNonStreamingModel.Raw;
        audio?: ChatCompletionAudioParam.Raw | null;
        frequency_penalty?: number | null;
        function_call?: CompletionCreateParamsNonStreamingFunctionCall.Raw | null;
        functions?: OpenaiTypesChatCompletionCreateParamsFunction.Raw[] | null;
        logit_bias?: Record<string, number | null | undefined> | null;
        logprobs?: boolean | null;
        max_completion_tokens?: number | null;
        max_tokens?: number | null;
        metadata?: Record<string, string | null | undefined> | null;
        modalities?: CompletionCreateParamsNonStreamingModalitiesItem.Raw[] | null;
        n?: number | null;
        parallel_tool_calls?: boolean | null;
        prediction?: ChatCompletionPredictionContentParam.Raw | null;
        presence_penalty?: number | null;
        reasoning_effort?: CompletionCreateParamsNonStreamingReasoningEffort.Raw | null;
        response_format?: CompletionCreateParamsNonStreamingResponseFormat.Raw | null;
        seed?: number | null;
        service_tier?: CompletionCreateParamsNonStreamingServiceTier.Raw | null;
        stop?: CompletionCreateParamsNonStreamingStop.Raw | null;
        store?: boolean | null;
        stream_options?: ChatCompletionStreamOptionsParam.Raw | null;
        temperature?: number | null;
        tool_choice?: CompletionCreateParamsNonStreamingToolChoice.Raw | null;
        tools?: ChatCompletionToolParam.Raw[] | null;
        top_logprobs?: number | null;
        top_p?: number | null;
        user?: string | null;
        stream?: boolean | null;
    }
}
