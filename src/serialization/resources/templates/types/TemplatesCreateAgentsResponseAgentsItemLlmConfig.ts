/**
 * This file was auto-generated by Fern from our API Definition.
 */

import * as serializers from "../../../index";
import * as Letta from "../../../../api/index";
import * as core from "../../../../core";
import { TemplatesCreateAgentsResponseAgentsItemLlmConfigModelEndpointType } from "./TemplatesCreateAgentsResponseAgentsItemLlmConfigModelEndpointType";
import { TemplatesCreateAgentsResponseAgentsItemLlmConfigModelEndpoint } from "./TemplatesCreateAgentsResponseAgentsItemLlmConfigModelEndpoint";
import { TemplatesCreateAgentsResponseAgentsItemLlmConfigModelWrapper } from "./TemplatesCreateAgentsResponseAgentsItemLlmConfigModelWrapper";
import { TemplatesCreateAgentsResponseAgentsItemLlmConfigPutInnerThoughtsInKwargs } from "./TemplatesCreateAgentsResponseAgentsItemLlmConfigPutInnerThoughtsInKwargs";
import { TemplatesCreateAgentsResponseAgentsItemLlmConfigHandle } from "./TemplatesCreateAgentsResponseAgentsItemLlmConfigHandle";
import { TemplatesCreateAgentsResponseAgentsItemLlmConfigTemperature } from "./TemplatesCreateAgentsResponseAgentsItemLlmConfigTemperature";
import { TemplatesCreateAgentsResponseAgentsItemLlmConfigMaxTokens } from "./TemplatesCreateAgentsResponseAgentsItemLlmConfigMaxTokens";

export const TemplatesCreateAgentsResponseAgentsItemLlmConfig: core.serialization.ObjectSchema<
    serializers.TemplatesCreateAgentsResponseAgentsItemLlmConfig.Raw,
    Letta.TemplatesCreateAgentsResponseAgentsItemLlmConfig
> = core.serialization.object({
    model: core.serialization.string(),
    modelEndpointType: core.serialization.property(
        "model_endpoint_type",
        TemplatesCreateAgentsResponseAgentsItemLlmConfigModelEndpointType,
    ),
    modelEndpoint: core.serialization.property(
        "model_endpoint",
        TemplatesCreateAgentsResponseAgentsItemLlmConfigModelEndpoint.optional(),
    ),
    modelWrapper: core.serialization.property(
        "model_wrapper",
        TemplatesCreateAgentsResponseAgentsItemLlmConfigModelWrapper.optional(),
    ),
    contextWindow: core.serialization.property("context_window", core.serialization.number()),
    putInnerThoughtsInKwargs: core.serialization.property(
        "put_inner_thoughts_in_kwargs",
        TemplatesCreateAgentsResponseAgentsItemLlmConfigPutInnerThoughtsInKwargs.optional(),
    ),
    handle: TemplatesCreateAgentsResponseAgentsItemLlmConfigHandle.optional(),
    temperature: TemplatesCreateAgentsResponseAgentsItemLlmConfigTemperature.optional(),
    maxTokens: core.serialization.property(
        "max_tokens",
        TemplatesCreateAgentsResponseAgentsItemLlmConfigMaxTokens.optional(),
    ),
});

export declare namespace TemplatesCreateAgentsResponseAgentsItemLlmConfig {
    export interface Raw {
        model: string;
        model_endpoint_type: TemplatesCreateAgentsResponseAgentsItemLlmConfigModelEndpointType.Raw;
        model_endpoint?: TemplatesCreateAgentsResponseAgentsItemLlmConfigModelEndpoint.Raw | null;
        model_wrapper?: TemplatesCreateAgentsResponseAgentsItemLlmConfigModelWrapper.Raw | null;
        context_window: number;
        put_inner_thoughts_in_kwargs?: TemplatesCreateAgentsResponseAgentsItemLlmConfigPutInnerThoughtsInKwargs.Raw | null;
        handle?: TemplatesCreateAgentsResponseAgentsItemLlmConfigHandle.Raw | null;
        temperature?: TemplatesCreateAgentsResponseAgentsItemLlmConfigTemperature.Raw | null;
        max_tokens?: TemplatesCreateAgentsResponseAgentsItemLlmConfigMaxTokens.Raw | null;
    }
}
