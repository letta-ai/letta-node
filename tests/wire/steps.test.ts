/**
 * This file was auto-generated by Fern from our API Definition.
 */

import { mockServerPool } from "../mock-server/MockServerPool";
import { LettaClient } from "../../src/Client";

describe("Steps", () => {
    test("list", async () => {
        const server = mockServerPool.createServer();
        const client = new LettaClient({ token: "test", project: "test", environment: server.baseUrl });

        const rawResponseBody = [
            {
                id: "id",
                origin: "origin",
                provider_id: "provider_id",
                job_id: "job_id",
                agent_id: "agent_id",
                provider_name: "provider_name",
                provider_category: "provider_category",
                model: "model",
                model_endpoint: "model_endpoint",
                context_window_limit: 1,
                completion_tokens: 1,
                prompt_tokens: 1,
                total_tokens: 1,
                completion_tokens_details: { key: "value" },
                stop_reason: "end_turn",
                tags: ["tags"],
                tid: "tid",
                trace_id: "trace_id",
                messages: [{ id: "message-123e4567-e89b-12d3-a456-426614174000", role: "assistant" }],
                feedback: "positive",
                project_id: "project_id",
            },
        ];
        server.mockEndpoint().get("/v1/steps/").respondWith().statusCode(200).jsonBody(rawResponseBody).build();

        const response = await client.steps.list();
        expect(response).toEqual([
            {
                id: "id",
                origin: "origin",
                provider_id: "provider_id",
                job_id: "job_id",
                agent_id: "agent_id",
                provider_name: "provider_name",
                provider_category: "provider_category",
                model: "model",
                model_endpoint: "model_endpoint",
                context_window_limit: 1,
                completion_tokens: 1,
                prompt_tokens: 1,
                total_tokens: 1,
                completion_tokens_details: {
                    key: "value",
                },
                stop_reason: "end_turn",
                tags: ["tags"],
                tid: "tid",
                trace_id: "trace_id",
                messages: [
                    {
                        id: "message-123e4567-e89b-12d3-a456-426614174000",
                        role: "assistant",
                    },
                ],
                feedback: "positive",
                project_id: "project_id",
            },
        ]);
    });

    test("retrieve", async () => {
        const server = mockServerPool.createServer();
        const client = new LettaClient({ token: "test", project: "test", environment: server.baseUrl });

        const rawResponseBody = {
            id: "id",
            origin: "origin",
            provider_id: "provider_id",
            job_id: "job_id",
            agent_id: "agent_id",
            provider_name: "provider_name",
            provider_category: "provider_category",
            model: "model",
            model_endpoint: "model_endpoint",
            context_window_limit: 1,
            completion_tokens: 1,
            prompt_tokens: 1,
            total_tokens: 1,
            completion_tokens_details: { key: "value" },
            stop_reason: "end_turn",
            tags: ["tags"],
            tid: "tid",
            trace_id: "trace_id",
            messages: [
                {
                    created_by_id: "created_by_id",
                    last_updated_by_id: "last_updated_by_id",
                    created_at: "2024-01-15T09:30:00Z",
                    updated_at: "2024-01-15T09:30:00Z",
                    id: "message-123e4567-e89b-12d3-a456-426614174000",
                    agent_id: "agent_id",
                    model: "model",
                    role: "assistant",
                    content: [{ type: "image", source: { type: "base64", media_type: "media_type", data: "data" } }],
                    name: "name",
                    tool_calls: [{ id: "id", function: { arguments: "arguments", name: "name" }, type: "function" }],
                    tool_call_id: "tool_call_id",
                    step_id: "step_id",
                    otid: "otid",
                    tool_returns: [{ status: "success" }],
                    group_id: "group_id",
                    sender_id: "sender_id",
                    batch_item_id: "batch_item_id",
                    is_err: true,
                },
            ],
            feedback: "positive",
            project_id: "project_id",
        };
        server.mockEndpoint().get("/v1/steps/step_id").respondWith().statusCode(200).jsonBody(rawResponseBody).build();

        const response = await client.steps.retrieve("step_id");
        expect(response).toEqual({
            id: "id",
            origin: "origin",
            provider_id: "provider_id",
            job_id: "job_id",
            agent_id: "agent_id",
            provider_name: "provider_name",
            provider_category: "provider_category",
            model: "model",
            model_endpoint: "model_endpoint",
            context_window_limit: 1,
            completion_tokens: 1,
            prompt_tokens: 1,
            total_tokens: 1,
            completion_tokens_details: {
                key: "value",
            },
            stop_reason: "end_turn",
            tags: ["tags"],
            tid: "tid",
            trace_id: "trace_id",
            messages: [
                {
                    created_by_id: "created_by_id",
                    last_updated_by_id: "last_updated_by_id",
                    created_at: "2024-01-15T09:30:00Z",
                    updated_at: "2024-01-15T09:30:00Z",
                    id: "message-123e4567-e89b-12d3-a456-426614174000",
                    agent_id: "agent_id",
                    model: "model",
                    role: "assistant",
                    content: [
                        {
                            type: "image",
                            source: {
                                type: "base64",
                                media_type: "media_type",
                                data: "data",
                            },
                        },
                    ],
                    name: "name",
                    tool_calls: [
                        {
                            id: "id",
                            function: {
                                arguments: "arguments",
                                name: "name",
                            },
                            type: "function",
                        },
                    ],
                    tool_call_id: "tool_call_id",
                    step_id: "step_id",
                    otid: "otid",
                    tool_returns: [
                        {
                            status: "success",
                        },
                    ],
                    group_id: "group_id",
                    sender_id: "sender_id",
                    batch_item_id: "batch_item_id",
                    is_err: true,
                },
            ],
            feedback: "positive",
            project_id: "project_id",
        });
    });
});
