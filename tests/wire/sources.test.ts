/**
 * This file was auto-generated by Fern from our API Definition.
 */

import { mockServerPool } from "../mock-server/MockServerPool";
import { LettaClient } from "../../src/Client";
import * as Letta from "../../src/api/index";

describe("Sources", () => {
    test("count", async () => {
        const server = mockServerPool.createServer();
        const client = new LettaClient({ token: "test", project: "test", environment: server.baseUrl });

        const rawResponseBody = 1;
        server.mockEndpoint().get("/v1/sources/count").respondWith().statusCode(200).jsonBody(rawResponseBody).build();

        const response = await client.sources.count();
        expect(response).toEqual(1);
    });

    test("retrieve", async () => {
        const server = mockServerPool.createServer();
        const client = new LettaClient({ token: "test", project: "test", environment: server.baseUrl });

        const rawResponseBody = {
            name: "name",
            description: "description",
            instructions: "instructions",
            metadata: { key: "value" },
            id: "source-123e4567-e89b-12d3-a456-426614174000",
            embedding_config: {
                embedding_endpoint_type: "openai",
                embedding_endpoint: "embedding_endpoint",
                embedding_model: "embedding_model",
                embedding_dim: 1,
                embedding_chunk_size: 1,
                handle: "handle",
                batch_size: 1,
                azure_endpoint: "azure_endpoint",
                azure_version: "azure_version",
                azure_deployment: "azure_deployment",
            },
            created_by_id: "created_by_id",
            last_updated_by_id: "last_updated_by_id",
            created_at: "2024-01-15T09:30:00Z",
            updated_at: "2024-01-15T09:30:00Z",
        };
        server
            .mockEndpoint()
            .get("/v1/sources/source_id")
            .respondWith()
            .statusCode(200)
            .jsonBody(rawResponseBody)
            .build();

        const response = await client.sources.retrieve("source_id");
        expect(response).toEqual({
            name: "name",
            description: "description",
            instructions: "instructions",
            metadata: {
                key: "value",
            },
            id: "source-123e4567-e89b-12d3-a456-426614174000",
            embedding_config: {
                embedding_endpoint_type: "openai",
                embedding_endpoint: "embedding_endpoint",
                embedding_model: "embedding_model",
                embedding_dim: 1,
                embedding_chunk_size: 1,
                handle: "handle",
                batch_size: 1,
                azure_endpoint: "azure_endpoint",
                azure_version: "azure_version",
                azure_deployment: "azure_deployment",
            },
            created_by_id: "created_by_id",
            last_updated_by_id: "last_updated_by_id",
            created_at: "2024-01-15T09:30:00Z",
            updated_at: "2024-01-15T09:30:00Z",
        });
    });

    test("delete", async () => {
        const server = mockServerPool.createServer();
        const client = new LettaClient({ token: "test", project: "test", environment: server.baseUrl });

        const rawResponseBody = { key: "value" };
        server
            .mockEndpoint()
            .delete("/v1/sources/source_id")
            .respondWith()
            .statusCode(200)
            .jsonBody(rawResponseBody)
            .build();

        const response = await client.sources.delete("source_id");
        expect(response).toEqual({
            key: "value",
        });
    });

    test("modify", async () => {
        const server = mockServerPool.createServer();
        const client = new LettaClient({ token: "test", project: "test", environment: server.baseUrl });
        const rawRequestBody = {};
        const rawResponseBody = {
            name: "name",
            description: "description",
            instructions: "instructions",
            metadata: { key: "value" },
            id: "source-123e4567-e89b-12d3-a456-426614174000",
            embedding_config: {
                embedding_endpoint_type: "openai",
                embedding_endpoint: "embedding_endpoint",
                embedding_model: "embedding_model",
                embedding_dim: 1,
                embedding_chunk_size: 1,
                handle: "handle",
                batch_size: 1,
                azure_endpoint: "azure_endpoint",
                azure_version: "azure_version",
                azure_deployment: "azure_deployment",
            },
            created_by_id: "created_by_id",
            last_updated_by_id: "last_updated_by_id",
            created_at: "2024-01-15T09:30:00Z",
            updated_at: "2024-01-15T09:30:00Z",
        };
        server
            .mockEndpoint()
            .patch("/v1/sources/source_id")
            .jsonBody(rawRequestBody)
            .respondWith()
            .statusCode(200)
            .jsonBody(rawResponseBody)
            .build();

        const response = await client.sources.modify("source_id", {});
        expect(response).toEqual({
            name: "name",
            description: "description",
            instructions: "instructions",
            metadata: {
                key: "value",
            },
            id: "source-123e4567-e89b-12d3-a456-426614174000",
            embedding_config: {
                embedding_endpoint_type: "openai",
                embedding_endpoint: "embedding_endpoint",
                embedding_model: "embedding_model",
                embedding_dim: 1,
                embedding_chunk_size: 1,
                handle: "handle",
                batch_size: 1,
                azure_endpoint: "azure_endpoint",
                azure_version: "azure_version",
                azure_deployment: "azure_deployment",
            },
            created_by_id: "created_by_id",
            last_updated_by_id: "last_updated_by_id",
            created_at: "2024-01-15T09:30:00Z",
            updated_at: "2024-01-15T09:30:00Z",
        });
    });

    test("retrieve_by_name", async () => {
        const server = mockServerPool.createServer();
        const client = new LettaClient({ token: "test", project: "test", environment: server.baseUrl });

        const rawResponseBody = "string";
        server
            .mockEndpoint()
            .get("/v1/sources/name/source_name")
            .respondWith()
            .statusCode(200)
            .jsonBody(rawResponseBody)
            .build();

        const response = await client.sources.retrieveByName("source_name");
        expect(response).toEqual("string");
    });

    test("get_sources_metadata", async () => {
        const server = mockServerPool.createServer();
        const client = new LettaClient({ token: "test", project: "test", environment: server.baseUrl });

        const rawResponseBody = {
            total_sources: 1,
            total_files: 1,
            total_size: 1,
            sources: [
                {
                    source_id: "source_id",
                    source_name: "source_name",
                    file_count: 1,
                    total_size: 1,
                    files: [{ file_id: "file_id", file_name: "file_name" }],
                },
            ],
        };
        server
            .mockEndpoint()
            .get("/v1/sources/metadata")
            .respondWith()
            .statusCode(200)
            .jsonBody(rawResponseBody)
            .build();

        const response = await client.sources.getSourcesMetadata();
        expect(response).toEqual({
            total_sources: 1,
            total_files: 1,
            total_size: 1,
            sources: [
                {
                    source_id: "source_id",
                    source_name: "source_name",
                    file_count: 1,
                    total_size: 1,
                    files: [
                        {
                            file_id: "file_id",
                            file_name: "file_name",
                        },
                    ],
                },
            ],
        });
    });

    test("list", async () => {
        const server = mockServerPool.createServer();
        const client = new LettaClient({ token: "test", project: "test", environment: server.baseUrl });

        const rawResponseBody = [
            {
                name: "name",
                description: "description",
                instructions: "instructions",
                metadata: { key: "value" },
                id: "source-123e4567-e89b-12d3-a456-426614174000",
                embedding_config: {
                    embedding_endpoint_type: "openai",
                    embedding_endpoint: "embedding_endpoint",
                    embedding_model: "embedding_model",
                    embedding_dim: 1,
                    embedding_chunk_size: 1,
                    handle: "handle",
                    batch_size: 1,
                    azure_endpoint: "azure_endpoint",
                    azure_version: "azure_version",
                    azure_deployment: "azure_deployment",
                },
                created_by_id: "created_by_id",
                last_updated_by_id: "last_updated_by_id",
                created_at: "2024-01-15T09:30:00Z",
                updated_at: "2024-01-15T09:30:00Z",
            },
        ];
        server.mockEndpoint().get("/v1/sources/").respondWith().statusCode(200).jsonBody(rawResponseBody).build();

        const response = await client.sources.list();
        expect(response).toEqual([
            {
                name: "name",
                description: "description",
                instructions: "instructions",
                metadata: {
                    key: "value",
                },
                id: "source-123e4567-e89b-12d3-a456-426614174000",
                embedding_config: {
                    embedding_endpoint_type: "openai",
                    embedding_endpoint: "embedding_endpoint",
                    embedding_model: "embedding_model",
                    embedding_dim: 1,
                    embedding_chunk_size: 1,
                    handle: "handle",
                    batch_size: 1,
                    azure_endpoint: "azure_endpoint",
                    azure_version: "azure_version",
                    azure_deployment: "azure_deployment",
                },
                created_by_id: "created_by_id",
                last_updated_by_id: "last_updated_by_id",
                created_at: "2024-01-15T09:30:00Z",
                updated_at: "2024-01-15T09:30:00Z",
            },
        ]);
    });

    test("create", async () => {
        const server = mockServerPool.createServer();
        const client = new LettaClient({ token: "test", project: "test", environment: server.baseUrl });
        const rawRequestBody = { name: "name" };
        const rawResponseBody = {
            name: "name",
            description: "description",
            instructions: "instructions",
            metadata: { key: "value" },
            id: "source-123e4567-e89b-12d3-a456-426614174000",
            embedding_config: {
                embedding_endpoint_type: "openai",
                embedding_endpoint: "embedding_endpoint",
                embedding_model: "embedding_model",
                embedding_dim: 1,
                embedding_chunk_size: 1,
                handle: "handle",
                batch_size: 1,
                azure_endpoint: "azure_endpoint",
                azure_version: "azure_version",
                azure_deployment: "azure_deployment",
            },
            created_by_id: "created_by_id",
            last_updated_by_id: "last_updated_by_id",
            created_at: "2024-01-15T09:30:00Z",
            updated_at: "2024-01-15T09:30:00Z",
        };
        server
            .mockEndpoint()
            .post("/v1/sources/")
            .jsonBody(rawRequestBody)
            .respondWith()
            .statusCode(200)
            .jsonBody(rawResponseBody)
            .build();

        const response = await client.sources.create({
            name: "name",
        });
        expect(response).toEqual({
            name: "name",
            description: "description",
            instructions: "instructions",
            metadata: {
                key: "value",
            },
            id: "source-123e4567-e89b-12d3-a456-426614174000",
            embedding_config: {
                embedding_endpoint_type: "openai",
                embedding_endpoint: "embedding_endpoint",
                embedding_model: "embedding_model",
                embedding_dim: 1,
                embedding_chunk_size: 1,
                handle: "handle",
                batch_size: 1,
                azure_endpoint: "azure_endpoint",
                azure_version: "azure_version",
                azure_deployment: "azure_deployment",
            },
            created_by_id: "created_by_id",
            last_updated_by_id: "last_updated_by_id",
            created_at: "2024-01-15T09:30:00Z",
            updated_at: "2024-01-15T09:30:00Z",
        });
    });

    test("get_agents_for_source", async () => {
        const server = mockServerPool.createServer();
        const client = new LettaClient({ token: "test", project: "test", environment: server.baseUrl });

        const rawResponseBody = ["string"];
        server
            .mockEndpoint()
            .get("/v1/sources/source_id/agents")
            .respondWith()
            .statusCode(200)
            .jsonBody(rawResponseBody)
            .build();

        const response = await client.sources.getAgentsForSource("source_id");
        expect(response).toEqual(["string"]);
    });

    test("get_file_metadata", async () => {
        const server = mockServerPool.createServer();
        const client = new LettaClient({ token: "test", project: "test", environment: server.baseUrl });

        const rawResponseBody = {
            source_id: "source_id",
            file_name: "file_name",
            original_file_name: "original_file_name",
            file_path: "file_path",
            file_type: "file_type",
            file_size: 1,
            file_creation_date: "file_creation_date",
            file_last_modified_date: "file_last_modified_date",
            processing_status: "pending",
            error_message: "error_message",
            total_chunks: 1,
            chunks_embedded: 1,
            content: "content",
            id: "file-123e4567-e89b-12d3-a456-426614174000",
            created_at: "2024-01-15T09:30:00Z",
            updated_at: "2024-01-15T09:30:00Z",
        };
        server
            .mockEndpoint()
            .get("/v1/sources/source_id/files/file_id")
            .respondWith()
            .statusCode(200)
            .jsonBody(rawResponseBody)
            .build();

        const response = await client.sources.getFileMetadata("source_id", "file_id");
        expect(response).toEqual({
            source_id: "source_id",
            file_name: "file_name",
            original_file_name: "original_file_name",
            file_path: "file_path",
            file_type: "file_type",
            file_size: 1,
            file_creation_date: "file_creation_date",
            file_last_modified_date: "file_last_modified_date",
            processing_status: "pending",
            error_message: "error_message",
            total_chunks: 1,
            chunks_embedded: 1,
            content: "content",
            id: "file-123e4567-e89b-12d3-a456-426614174000",
            created_at: "2024-01-15T09:30:00Z",
            updated_at: "2024-01-15T09:30:00Z",
        });
    });
});
