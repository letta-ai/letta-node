/**
 * This file was auto-generated by Fern from our API Definition.
 */

import { mockServerPool } from "../../mock-server/MockServerPool";
import { LettaClient } from "../../../src/Client";

describe("Passages", () => {
    test("list", async () => {
        const server = mockServerPool.createServer();
        const client = new LettaClient({ token: "test", project: "test", environment: server.baseUrl });

        const rawResponseBody = [
            {
                created_by_id: "created_by_id",
                last_updated_by_id: "last_updated_by_id",
                created_at: "2024-01-15T09:30:00Z",
                updated_at: "2024-01-15T09:30:00Z",
                is_deleted: true,
                agent_id: "agent_id",
                source_id: "source_id",
                file_id: "file_id",
                file_name: "file_name",
                metadata: { key: "value" },
                id: "passage-123e4567-e89b-12d3-a456-426614174000",
                text: "text",
                embedding: [1.1],
                embedding_config: {
                    embedding_endpoint_type: "openai",
                    embedding_endpoint: "embedding_endpoint",
                    embedding_model: "embedding_model",
                    embedding_dim: 1,
                    embedding_chunk_size: 1,
                    handle: "handle",
                    batch_size: 1,
                    azure_endpoint: "azure_endpoint",
                    azure_version: "azure_version",
                    azure_deployment: "azure_deployment",
                },
            },
        ];
        server
            .mockEndpoint()
            .get("/v1/agents/agent_id/archival-memory")
            .respondWith()
            .statusCode(200)
            .jsonBody(rawResponseBody)
            .build();

        const response = await client.agents.passages.list("agent_id");
        expect(response).toEqual([
            {
                created_by_id: "created_by_id",
                last_updated_by_id: "last_updated_by_id",
                created_at: "2024-01-15T09:30:00Z",
                updated_at: "2024-01-15T09:30:00Z",
                is_deleted: true,
                agent_id: "agent_id",
                source_id: "source_id",
                file_id: "file_id",
                file_name: "file_name",
                metadata: {
                    key: "value",
                },
                id: "passage-123e4567-e89b-12d3-a456-426614174000",
                text: "text",
                embedding: [1.1],
                embedding_config: {
                    embedding_endpoint_type: "openai",
                    embedding_endpoint: "embedding_endpoint",
                    embedding_model: "embedding_model",
                    embedding_dim: 1,
                    embedding_chunk_size: 1,
                    handle: "handle",
                    batch_size: 1,
                    azure_endpoint: "azure_endpoint",
                    azure_version: "azure_version",
                    azure_deployment: "azure_deployment",
                },
            },
        ]);
    });

    test("create", async () => {
        const server = mockServerPool.createServer();
        const client = new LettaClient({ token: "test", project: "test", environment: server.baseUrl });
        const rawRequestBody = { text: "text" };
        const rawResponseBody = [
            {
                created_by_id: "created_by_id",
                last_updated_by_id: "last_updated_by_id",
                created_at: "2024-01-15T09:30:00Z",
                updated_at: "2024-01-15T09:30:00Z",
                is_deleted: true,
                agent_id: "agent_id",
                source_id: "source_id",
                file_id: "file_id",
                file_name: "file_name",
                metadata: { key: "value" },
                id: "passage-123e4567-e89b-12d3-a456-426614174000",
                text: "text",
                embedding: [1.1],
                embedding_config: {
                    embedding_endpoint_type: "openai",
                    embedding_endpoint: "embedding_endpoint",
                    embedding_model: "embedding_model",
                    embedding_dim: 1,
                    embedding_chunk_size: 1,
                    handle: "handle",
                    batch_size: 1,
                    azure_endpoint: "azure_endpoint",
                    azure_version: "azure_version",
                    azure_deployment: "azure_deployment",
                },
            },
        ];
        server
            .mockEndpoint()
            .post("/v1/agents/agent_id/archival-memory")
            .jsonBody(rawRequestBody)
            .respondWith()
            .statusCode(200)
            .jsonBody(rawResponseBody)
            .build();

        const response = await client.agents.passages.create("agent_id", {
            text: "text",
        });
        expect(response).toEqual([
            {
                created_by_id: "created_by_id",
                last_updated_by_id: "last_updated_by_id",
                created_at: "2024-01-15T09:30:00Z",
                updated_at: "2024-01-15T09:30:00Z",
                is_deleted: true,
                agent_id: "agent_id",
                source_id: "source_id",
                file_id: "file_id",
                file_name: "file_name",
                metadata: {
                    key: "value",
                },
                id: "passage-123e4567-e89b-12d3-a456-426614174000",
                text: "text",
                embedding: [1.1],
                embedding_config: {
                    embedding_endpoint_type: "openai",
                    embedding_endpoint: "embedding_endpoint",
                    embedding_model: "embedding_model",
                    embedding_dim: 1,
                    embedding_chunk_size: 1,
                    handle: "handle",
                    batch_size: 1,
                    azure_endpoint: "azure_endpoint",
                    azure_version: "azure_version",
                    azure_deployment: "azure_deployment",
                },
            },
        ]);
    });

    test("delete", async () => {
        const server = mockServerPool.createServer();
        const client = new LettaClient({ token: "test", project: "test", environment: server.baseUrl });

        const rawResponseBody = { key: "value" };
        server
            .mockEndpoint()
            .delete("/v1/agents/agent_id/archival-memory/memory_id")
            .respondWith()
            .statusCode(200)
            .jsonBody(rawResponseBody)
            .build();

        const response = await client.agents.passages.delete("agent_id", "memory_id");
        expect(response).toEqual({
            key: "value",
        });
    });

    test("modify", async () => {
        const server = mockServerPool.createServer();
        const client = new LettaClient({ token: "test", project: "test", environment: server.baseUrl });
        const rawRequestBody = { id: "id" };
        const rawResponseBody = [
            {
                created_by_id: "created_by_id",
                last_updated_by_id: "last_updated_by_id",
                created_at: "2024-01-15T09:30:00Z",
                updated_at: "2024-01-15T09:30:00Z",
                is_deleted: true,
                agent_id: "agent_id",
                source_id: "source_id",
                file_id: "file_id",
                file_name: "file_name",
                metadata: { key: "value" },
                id: "passage-123e4567-e89b-12d3-a456-426614174000",
                text: "text",
                embedding: [1.1],
                embedding_config: {
                    embedding_endpoint_type: "openai",
                    embedding_endpoint: "embedding_endpoint",
                    embedding_model: "embedding_model",
                    embedding_dim: 1,
                    embedding_chunk_size: 1,
                    handle: "handle",
                    batch_size: 1,
                    azure_endpoint: "azure_endpoint",
                    azure_version: "azure_version",
                    azure_deployment: "azure_deployment",
                },
            },
        ];
        server
            .mockEndpoint()
            .patch("/v1/agents/agent_id/archival-memory/memory_id")
            .jsonBody(rawRequestBody)
            .respondWith()
            .statusCode(200)
            .jsonBody(rawResponseBody)
            .build();

        const response = await client.agents.passages.modify("agent_id", "memory_id", {
            id: "id",
        });
        expect(response).toEqual([
            {
                created_by_id: "created_by_id",
                last_updated_by_id: "last_updated_by_id",
                created_at: "2024-01-15T09:30:00Z",
                updated_at: "2024-01-15T09:30:00Z",
                is_deleted: true,
                agent_id: "agent_id",
                source_id: "source_id",
                file_id: "file_id",
                file_name: "file_name",
                metadata: {
                    key: "value",
                },
                id: "passage-123e4567-e89b-12d3-a456-426614174000",
                text: "text",
                embedding: [1.1],
                embedding_config: {
                    embedding_endpoint_type: "openai",
                    embedding_endpoint: "embedding_endpoint",
                    embedding_model: "embedding_model",
                    embedding_dim: 1,
                    embedding_chunk_size: 1,
                    handle: "handle",
                    batch_size: 1,
                    azure_endpoint: "azure_endpoint",
                    azure_version: "azure_version",
                    azure_deployment: "azure_deployment",
                },
            },
        ]);
    });
});
