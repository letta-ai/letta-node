/**
 * This file was auto-generated by Fern from our API Definition.
 */

import { mockServerPool } from "../../mock-server/MockServerPool";
import { LettaClient } from "../../../src/Client";

describe("Messages", () => {
    test("list", async () => {
        const server = mockServerPool.createServer();
        const client = new LettaClient({ token: "test", project: "test", environment: server.baseUrl });

        const rawResponseBody = [
            {
                id: "id",
                date: "2024-01-15T09:30:00Z",
                name: "name",
                message_type: "system_message",
                otid: "otid",
                sender_id: "sender_id",
                step_id: "step_id",
                is_err: true,
                content: "content",
            },
        ];
        server
            .mockEndpoint()
            .get("/v1/agents/agent_id/messages")
            .respondWith()
            .statusCode(200)
            .jsonBody(rawResponseBody)
            .build();

        const response = await client.agents.messages.list("agent_id");
        expect(response).toEqual([
            {
                id: "id",
                date: "2024-01-15T09:30:00Z",
                name: "name",
                message_type: "system_message",
                otid: "otid",
                sender_id: "sender_id",
                step_id: "step_id",
                is_err: true,
                content: "content",
            },
        ]);
    });

    test("create", async () => {
        const server = mockServerPool.createServer();
        const client = new LettaClient({ token: "test", project: "test", environment: server.baseUrl });
        const rawRequestBody = { messages: [{ role: "user", content: [{ type: "text", text: "text" }] }] };
        const rawResponseBody = {
            messages: [
                {
                    id: "id",
                    date: "2024-01-15T09:30:00Z",
                    name: "name",
                    message_type: "system_message",
                    otid: "otid",
                    sender_id: "sender_id",
                    step_id: "step_id",
                    is_err: true,
                    content: "content",
                },
            ],
            stop_reason: { message_type: "stop_reason", stop_reason: "end_turn" },
            usage: {
                message_type: "usage_statistics",
                completion_tokens: 1,
                prompt_tokens: 1,
                total_tokens: 1,
                step_count: 1,
                steps_messages: [[{ id: "message-123e4567-e89b-12d3-a456-426614174000", role: "assistant" }]],
                run_ids: ["run_ids"],
            },
        };
        server
            .mockEndpoint()
            .post("/v1/agents/agent_id/messages")
            .jsonBody(rawRequestBody)
            .respondWith()
            .statusCode(200)
            .jsonBody(rawResponseBody)
            .build();

        const response = await client.agents.messages.create("agent_id", {
            messages: [
                {
                    role: "user",
                    content: [
                        {
                            type: "text",
                            text: "text",
                        },
                    ],
                },
            ],
        });
        expect(response).toEqual({
            messages: [
                {
                    id: "id",
                    date: "2024-01-15T09:30:00Z",
                    name: "name",
                    message_type: "system_message",
                    otid: "otid",
                    sender_id: "sender_id",
                    step_id: "step_id",
                    is_err: true,
                    content: "content",
                },
            ],
            stop_reason: {
                message_type: "stop_reason",
                stop_reason: "end_turn",
            },
            usage: {
                message_type: "usage_statistics",
                completion_tokens: 1,
                prompt_tokens: 1,
                total_tokens: 1,
                step_count: 1,
                steps_messages: [
                    [
                        {
                            id: "message-123e4567-e89b-12d3-a456-426614174000",
                            role: "assistant",
                        },
                    ],
                ],
                run_ids: ["run_ids"],
            },
        });
    });

    test("modify", async () => {
        const server = mockServerPool.createServer();
        const client = new LettaClient({ token: "test", project: "test", environment: server.baseUrl });
        const rawRequestBody = { content: "content" };
        const rawResponseBody = {
            id: "id",
            date: "2024-01-15T09:30:00Z",
            name: "name",
            message_type: "system_message",
            otid: "otid",
            sender_id: "sender_id",
            step_id: "step_id",
            is_err: true,
            content: "content",
        };
        server
            .mockEndpoint()
            .patch("/v1/agents/agent_id/messages/message_id")
            .jsonBody(rawRequestBody)
            .respondWith()
            .statusCode(200)
            .jsonBody(rawResponseBody)
            .build();

        const response = await client.agents.messages.modify("agent_id", "message_id", {
            content: "content",
        });
        expect(response).toEqual({
            id: "id",
            date: "2024-01-15T09:30:00Z",
            name: "name",
            message_type: "system_message",
            otid: "otid",
            sender_id: "sender_id",
            step_id: "step_id",
            is_err: true,
            content: "content",
        });
    });

    test("cancel", async () => {
        const server = mockServerPool.createServer();
        const client = new LettaClient({ token: "test", project: "test", environment: server.baseUrl });
        const rawRequestBody = undefined;
        const rawResponseBody = { key: "value" };
        server
            .mockEndpoint()
            .post("/v1/agents/agent_id/messages/cancel")
            .jsonBody(rawRequestBody)
            .respondWith()
            .statusCode(200)
            .jsonBody(rawResponseBody)
            .build();

        const response = await client.agents.messages.cancel("agent_id", undefined);
        expect(response).toEqual({
            key: "value",
        });
    });

    test("create_async", async () => {
        const server = mockServerPool.createServer();
        const client = new LettaClient({ token: "test", project: "test", environment: server.baseUrl });
        const rawRequestBody = { messages: [{ role: "user", content: [{ type: "text", text: "text" }] }] };
        const rawResponseBody = {
            created_by_id: "created_by_id",
            last_updated_by_id: "last_updated_by_id",
            created_at: "2024-01-15T09:30:00Z",
            updated_at: "2024-01-15T09:30:00Z",
            status: "created",
            completed_at: "2024-01-15T09:30:00Z",
            metadata: { key: "value" },
            job_type: "job",
            callback_url: "callback_url",
            callback_sent_at: "2024-01-15T09:30:00Z",
            callback_status_code: 1,
            callback_error: "callback_error",
            id: "run-123e4567-e89b-12d3-a456-426614174000",
            request_config: {
                use_assistant_message: true,
                assistant_message_tool_name: "assistant_message_tool_name",
                assistant_message_tool_kwarg: "assistant_message_tool_kwarg",
                include_return_message_types: ["system_message"],
            },
        };
        server
            .mockEndpoint()
            .post("/v1/agents/agent_id/messages/async")
            .jsonBody(rawRequestBody)
            .respondWith()
            .statusCode(200)
            .jsonBody(rawResponseBody)
            .build();

        const response = await client.agents.messages.createAsync("agent_id", {
            messages: [
                {
                    role: "user",
                    content: [
                        {
                            type: "text",
                            text: "text",
                        },
                    ],
                },
            ],
        });
        expect(response).toEqual({
            created_by_id: "created_by_id",
            last_updated_by_id: "last_updated_by_id",
            created_at: "2024-01-15T09:30:00Z",
            updated_at: "2024-01-15T09:30:00Z",
            status: "created",
            completed_at: "2024-01-15T09:30:00Z",
            metadata: {
                key: "value",
            },
            job_type: "job",
            callback_url: "callback_url",
            callback_sent_at: "2024-01-15T09:30:00Z",
            callback_status_code: 1,
            callback_error: "callback_error",
            id: "run-123e4567-e89b-12d3-a456-426614174000",
            request_config: {
                use_assistant_message: true,
                assistant_message_tool_name: "assistant_message_tool_name",
                assistant_message_tool_kwarg: "assistant_message_tool_kwarg",
                include_return_message_types: ["system_message"],
            },
        });
    });

    test("reset", async () => {
        const server = mockServerPool.createServer();
        const client = new LettaClient({ token: "test", project: "test", environment: server.baseUrl });

        const rawResponseBody = {
            created_by_id: "created_by_id",
            last_updated_by_id: "last_updated_by_id",
            created_at: "2024-01-15T09:30:00Z",
            updated_at: "2024-01-15T09:30:00Z",
            id: "id",
            name: "name",
            tool_rules: [
                {
                    tool_name: "tool_name",
                    type: "conditional",
                    prompt_template: "prompt_template",
                    default_child: "default_child",
                    child_output_mapping: { key: "value" },
                    require_output_mapping: true,
                },
            ],
            message_ids: ["message_ids"],
            system: "system",
            agent_type: "memgpt_agent",
            llm_config: {
                model: "model",
                model_endpoint_type: "openai",
                model_endpoint: "model_endpoint",
                provider_name: "provider_name",
                provider_category: "base",
                model_wrapper: "model_wrapper",
                context_window: 1,
                put_inner_thoughts_in_kwargs: true,
                handle: "handle",
                temperature: 1.1,
                max_tokens: 1,
                enable_reasoner: true,
                reasoning_effort: "low",
                max_reasoning_tokens: 1,
                frequency_penalty: 1.1,
                compatibility_type: "gguf",
            },
            embedding_config: {
                embedding_endpoint_type: "openai",
                embedding_endpoint: "embedding_endpoint",
                embedding_model: "embedding_model",
                embedding_dim: 1,
                embedding_chunk_size: 1,
                handle: "handle",
                batch_size: 1,
                azure_endpoint: "azure_endpoint",
                azure_version: "azure_version",
                azure_deployment: "azure_deployment",
            },
            response_format: { type: "json_object" },
            description: "description",
            metadata: { key: "value" },
            memory: {
                blocks: [{ value: "value", id: "block-123e4567-e89b-12d3-a456-426614174000" }],
                file_blocks: [
                    {
                        value: "value",
                        id: "block-123e4567-e89b-12d3-a456-426614174000",
                        file_id: "file_id",
                        source_id: "source_id",
                        is_open: true,
                    },
                ],
                prompt_template: "prompt_template",
            },
            tools: [
                {
                    id: "tool-123e4567-e89b-12d3-a456-426614174000",
                    tool_type: "custom",
                    description: "description",
                    source_type: "source_type",
                    name: "name",
                    tags: ["tags"],
                    source_code: "source_code",
                    json_schema: { key: "value" },
                    args_json_schema: { key: "value" },
                    return_char_limit: 1,
                    pip_requirements: [{ name: "name" }],
                    created_by_id: "created_by_id",
                    last_updated_by_id: "last_updated_by_id",
                    metadata_: { key: "value" },
                },
            ],
            sources: [
                {
                    name: "name",
                    description: "description",
                    instructions: "instructions",
                    metadata: { key: "value" },
                    id: "source-123e4567-e89b-12d3-a456-426614174000",
                    embedding_config: {
                        embedding_endpoint_type: "openai",
                        embedding_model: "embedding_model",
                        embedding_dim: 1,
                    },
                    created_by_id: "created_by_id",
                    last_updated_by_id: "last_updated_by_id",
                    created_at: "2024-01-15T09:30:00Z",
                    updated_at: "2024-01-15T09:30:00Z",
                },
            ],
            tags: ["tags"],
            tool_exec_environment_variables: [
                {
                    created_by_id: "created_by_id",
                    last_updated_by_id: "last_updated_by_id",
                    created_at: "2024-01-15T09:30:00Z",
                    updated_at: "2024-01-15T09:30:00Z",
                    id: "agent-env-123e4567-e89b-12d3-a456-426614174000",
                    key: "key",
                    value: "value",
                    description: "description",
                    agent_id: "agent_id",
                },
            ],
            project_id: "project_id",
            template_id: "template_id",
            base_template_id: "base_template_id",
            identity_ids: ["identity_ids"],
            message_buffer_autoclear: true,
            enable_sleeptime: true,
            multi_agent_group: {
                id: "id",
                manager_type: "round_robin",
                agent_ids: ["agent_ids"],
                description: "description",
                project_id: "project_id",
                shared_block_ids: ["shared_block_ids"],
                manager_agent_id: "manager_agent_id",
                termination_token: "termination_token",
                max_turns: 1,
                sleeptime_agent_frequency: 1,
                turns_counter: 1,
                last_processed_message_id: "last_processed_message_id",
                max_message_buffer_length: 1,
                min_message_buffer_length: 1,
            },
            last_run_completion: "2024-01-15T09:30:00Z",
            last_run_duration_ms: 1,
            timezone: "timezone",
            max_files_open: 1,
            per_file_view_window_char_limit: 1,
        };
        server
            .mockEndpoint()
            .patch("/v1/agents/agent_id/reset-messages")
            .respondWith()
            .statusCode(200)
            .jsonBody(rawResponseBody)
            .build();

        const response = await client.agents.messages.reset("agent_id");
        expect(response).toEqual({
            created_by_id: "created_by_id",
            last_updated_by_id: "last_updated_by_id",
            created_at: "2024-01-15T09:30:00Z",
            updated_at: "2024-01-15T09:30:00Z",
            id: "id",
            name: "name",
            tool_rules: [
                {
                    tool_name: "tool_name",
                    type: "conditional",
                    prompt_template: "prompt_template",
                    default_child: "default_child",
                    child_output_mapping: {
                        key: "value",
                    },
                    require_output_mapping: true,
                },
            ],
            message_ids: ["message_ids"],
            system: "system",
            agent_type: "memgpt_agent",
            llm_config: {
                model: "model",
                model_endpoint_type: "openai",
                model_endpoint: "model_endpoint",
                provider_name: "provider_name",
                provider_category: "base",
                model_wrapper: "model_wrapper",
                context_window: 1,
                put_inner_thoughts_in_kwargs: true,
                handle: "handle",
                temperature: 1.1,
                max_tokens: 1,
                enable_reasoner: true,
                reasoning_effort: "low",
                max_reasoning_tokens: 1,
                frequency_penalty: 1.1,
                compatibility_type: "gguf",
            },
            embedding_config: {
                embedding_endpoint_type: "openai",
                embedding_endpoint: "embedding_endpoint",
                embedding_model: "embedding_model",
                embedding_dim: 1,
                embedding_chunk_size: 1,
                handle: "handle",
                batch_size: 1,
                azure_endpoint: "azure_endpoint",
                azure_version: "azure_version",
                azure_deployment: "azure_deployment",
            },
            response_format: {
                type: "json_object",
            },
            description: "description",
            metadata: {
                key: "value",
            },
            memory: {
                blocks: [
                    {
                        value: "value",
                        id: "block-123e4567-e89b-12d3-a456-426614174000",
                    },
                ],
                file_blocks: [
                    {
                        value: "value",
                        id: "block-123e4567-e89b-12d3-a456-426614174000",
                        file_id: "file_id",
                        source_id: "source_id",
                        is_open: true,
                    },
                ],
                prompt_template: "prompt_template",
            },
            tools: [
                {
                    id: "tool-123e4567-e89b-12d3-a456-426614174000",
                    tool_type: "custom",
                    description: "description",
                    source_type: "source_type",
                    name: "name",
                    tags: ["tags"],
                    source_code: "source_code",
                    json_schema: {
                        key: "value",
                    },
                    args_json_schema: {
                        key: "value",
                    },
                    return_char_limit: 1,
                    pip_requirements: [
                        {
                            name: "name",
                        },
                    ],
                    created_by_id: "created_by_id",
                    last_updated_by_id: "last_updated_by_id",
                    metadata_: {
                        key: "value",
                    },
                },
            ],
            sources: [
                {
                    name: "name",
                    description: "description",
                    instructions: "instructions",
                    metadata: {
                        key: "value",
                    },
                    id: "source-123e4567-e89b-12d3-a456-426614174000",
                    embedding_config: {
                        embedding_endpoint_type: "openai",
                        embedding_model: "embedding_model",
                        embedding_dim: 1,
                    },
                    created_by_id: "created_by_id",
                    last_updated_by_id: "last_updated_by_id",
                    created_at: "2024-01-15T09:30:00Z",
                    updated_at: "2024-01-15T09:30:00Z",
                },
            ],
            tags: ["tags"],
            tool_exec_environment_variables: [
                {
                    created_by_id: "created_by_id",
                    last_updated_by_id: "last_updated_by_id",
                    created_at: "2024-01-15T09:30:00Z",
                    updated_at: "2024-01-15T09:30:00Z",
                    id: "agent-env-123e4567-e89b-12d3-a456-426614174000",
                    key: "key",
                    value: "value",
                    description: "description",
                    agent_id: "agent_id",
                },
            ],
            project_id: "project_id",
            template_id: "template_id",
            base_template_id: "base_template_id",
            identity_ids: ["identity_ids"],
            message_buffer_autoclear: true,
            enable_sleeptime: true,
            multi_agent_group: {
                id: "id",
                manager_type: "round_robin",
                agent_ids: ["agent_ids"],
                description: "description",
                project_id: "project_id",
                shared_block_ids: ["shared_block_ids"],
                manager_agent_id: "manager_agent_id",
                termination_token: "termination_token",
                max_turns: 1,
                sleeptime_agent_frequency: 1,
                turns_counter: 1,
                last_processed_message_id: "last_processed_message_id",
                max_message_buffer_length: 1,
                min_message_buffer_length: 1,
            },
            last_run_completion: "2024-01-15T09:30:00Z",
            last_run_duration_ms: 1,
            timezone: "timezone",
            max_files_open: 1,
            per_file_view_window_char_limit: 1,
        });
    });

    test("preview_raw_payload", async () => {
        const server = mockServerPool.createServer();
        const client = new LettaClient({ token: "test", project: "test", environment: server.baseUrl });
        const rawRequestBody = { messages: [{ role: "user", content: [{ type: "text", text: "text" }] }] };
        const rawResponseBody = { key: "value" };
        server
            .mockEndpoint()
            .post("/v1/agents/agent_id/messages/preview-raw-payload")
            .jsonBody(rawRequestBody)
            .respondWith()
            .statusCode(200)
            .jsonBody(rawResponseBody)
            .build();

        const response = await client.agents.messages.previewRawPayload("agent_id", {
            messages: [
                {
                    role: "user",
                    content: [
                        {
                            type: "text",
                            text: "text",
                        },
                    ],
                },
            ],
        });
        expect(response).toEqual({
            key: "value",
        });
    });
});
