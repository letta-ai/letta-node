/**
 * This file was auto-generated by Fern from our API Definition.
 */

import { mockServerPool } from "../mock-server/MockServerPool";
import { LettaClient } from "../../src/Client";

describe("EmbeddingModels", () => {
    test("list", async () => {
        const server = mockServerPool.createServer();
        const client = new LettaClient({ token: "test", project: "test", environment: server.baseUrl });

        const rawResponseBody = [
            {
                embedding_endpoint_type: "openai",
                embedding_endpoint: "embedding_endpoint",
                embedding_model: "embedding_model",
                embedding_dim: 1,
                embedding_chunk_size: 1,
                handle: "handle",
                batch_size: 1,
                azure_endpoint: "azure_endpoint",
                azure_version: "azure_version",
                azure_deployment: "azure_deployment",
            },
        ];
        server
            .mockEndpoint()
            .get("/v1/models/embedding")
            .respondWith()
            .statusCode(200)
            .jsonBody(rawResponseBody)
            .build();

        const response = await client.embeddingModels.list();
        expect(response).toEqual([
            {
                embedding_endpoint_type: "openai",
                embedding_endpoint: "embedding_endpoint",
                embedding_model: "embedding_model",
                embedding_dim: 1,
                embedding_chunk_size: 1,
                handle: "handle",
                batch_size: 1,
                azure_endpoint: "azure_endpoint",
                azure_version: "azure_version",
                azure_deployment: "azure_deployment",
            },
        ]);
    });
});
