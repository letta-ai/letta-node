/**
 * This file was auto-generated by Fern from our API Definition.
 */

import { mockServerPool } from "../../mock-server/MockServerPool";
import { LettaClient } from "../../../src/Client";

describe("Steps", () => {
    test("list", async () => {
        const server = mockServerPool.createServer();
        const client = new LettaClient({ token: "test", project: "test", environment: server.baseUrl });

        const rawResponseBody = [
            {
                id: "id",
                origin: "origin",
                provider_id: "provider_id",
                job_id: "job_id",
                agent_id: "agent_id",
                provider_name: "provider_name",
                provider_category: "provider_category",
                model: "model",
                model_endpoint: "model_endpoint",
                context_window_limit: 1,
                completion_tokens: 1,
                prompt_tokens: 1,
                total_tokens: 1,
                completion_tokens_details: { key: "value" },
                stop_reason: "end_turn",
                tags: ["tags"],
                tid: "tid",
                trace_id: "trace_id",
                messages: [{ id: "message-123e4567-e89b-12d3-a456-426614174000", role: "assistant" }],
                feedback: "positive",
                project_id: "project_id",
            },
        ];
        server
            .mockEndpoint()
            .get("/v1/runs/run_id/steps")
            .respondWith()
            .statusCode(200)
            .jsonBody(rawResponseBody)
            .build();

        const response = await client.runs.steps.list("run_id");
        expect(response).toEqual([
            {
                id: "id",
                origin: "origin",
                provider_id: "provider_id",
                job_id: "job_id",
                agent_id: "agent_id",
                provider_name: "provider_name",
                provider_category: "provider_category",
                model: "model",
                model_endpoint: "model_endpoint",
                context_window_limit: 1,
                completion_tokens: 1,
                prompt_tokens: 1,
                total_tokens: 1,
                completion_tokens_details: {
                    key: "value",
                },
                stop_reason: "end_turn",
                tags: ["tags"],
                tid: "tid",
                trace_id: "trace_id",
                messages: [
                    {
                        id: "message-123e4567-e89b-12d3-a456-426614174000",
                        role: "assistant",
                    },
                ],
                feedback: "positive",
                project_id: "project_id",
            },
        ]);
    });
});
